{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29f4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4491674",
   "metadata": {},
   "source": [
    "# 1. Codeup Blog Articles\n",
    "\n",
    "## Visit Codeup's Blog and record the urls for at least 5 distinct blog posts. For each post, you should scrape at least the post's title and content.\n",
    "\n",
    "## Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:\n",
    "\n",
    "\n",
    "{\n",
    "    'title': 'the title of the article',\n",
    "    'content': 'the full text content of the article'\n",
    "}\n",
    "## Plus any additional properties you think might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "446a27c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Spotlight on APIDA Voices: Celebrating Heritage and Inspiring Change ft. Arbeena Thapa',\n",
       "  'content': <a href=\"https://codeup.edu/featured/apida-heritage-month/\">Spotlight on APIDA Voices: Celebrating Heritage and Inspiring Change ft. Arbeena Thapa</a>},\n",
       " {'title': 'Women in tech: Panelist Spotlight – Magdalena Rahn',\n",
       "  'content': <a href=\"https://codeup.edu/featured/women-in-tech-panelist-spotlight/\">Women in tech: Panelist Spotlight – Magdalena Rahn</a>},\n",
       " {'title': 'Women in tech: Panelist Spotlight – Rachel Robbins-Mayhill',\n",
       "  'content': <a href=\"https://codeup.edu/featured/women-in-tech-rachel-robbins-mayhill/\">Women in tech: Panelist Spotlight – Rachel Robbins-Mayhill</a>},\n",
       " {'title': 'Women in Tech: Panelist Spotlight – Sarah Mellor',\n",
       "  'content': <a href=\"https://codeup.edu/codeup-news/women-in-tech-panelist-spotlight-sarah-mellor/\">Women in Tech: Panelist Spotlight – Sarah Mellor</a>},\n",
       " {'title': 'Women in Tech: Panelist Spotlight – Madeleine Capper',\n",
       "  'content': <a href=\"https://codeup.edu/events/women-in-tech-madeleine/\">Women in Tech: Panelist Spotlight – Madeleine Capper</a>},\n",
       " {'title': 'Black Excellence in Tech: Panelist Spotlight – Wilmarie De La Cruz Mejia',\n",
       "  'content': <a href=\"https://codeup.edu/codeup-news/panelist-spotlight-4/\">Black Excellence in Tech: Panelist Spotlight – Wilmarie De La Cruz Mejia</a>},\n",
       " {'title': 'Git Codeupdates', 'content': None}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://codeup.com/blog/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "response = get(url, headers=headers)\n",
    "\n",
    "# Parse the HTML content of the webpage\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the articles on the page\n",
    "articles = soup.find_all('h2')\n",
    "\n",
    "# Initialize a list to store the article information\n",
    "article_list = []\n",
    "\n",
    "# Loop through each article\n",
    "for article in articles:\n",
    "    # Extract the title and content\n",
    "    title = article.get_text()\n",
    "    links = article.find('a')\n",
    "    url = new_links[0]\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Create a dictionary for each article\n",
    "    article_data = {\n",
    "        'title': title,\n",
    "        'content': content\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    article_list.append(article_data)\n",
    "\n",
    "article_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00b69be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_links():\n",
    "    \n",
    "    url = 'https://codeup.edu/blog/'\n",
    "\n",
    "    #user with access to webpage\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "    response = get(url, headers=headers)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    links = soup.find_all(\"h2\")\n",
    "        \n",
    "    new_links = []\n",
    "\n",
    "    for article in links:\n",
    "        \n",
    "        if article.find(\"a\"):\n",
    "\n",
    "            new_links.append(article.find(\"a\").get(\"href\")) \n",
    "        \n",
    "    return links, new_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "afad2013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://codeup.edu/featured/apida-heritage-month/',\n",
       " 'https://codeup.edu/featured/women-in-tech-panelist-spotlight/',\n",
       " 'https://codeup.edu/featured/women-in-tech-rachel-robbins-mayhill/',\n",
       " 'https://codeup.edu/codeup-news/women-in-tech-panelist-spotlight-sarah-mellor/',\n",
       " 'https://codeup.edu/events/women-in-tech-madeleine/',\n",
       " 'https://codeup.edu/codeup-news/panelist-spotlight-4/']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links, new_links = get_blog_links()\n",
    "new_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "573c4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blog_titles():\n",
    "    \n",
    "    links, new_links = get_blog_links()\n",
    "    \n",
    "    titles = []\n",
    "    \n",
    "    for article in links:\n",
    "        \n",
    "        titles.append(article.get_text())\n",
    "        \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be593bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spotlight on APIDA Voices: Celebrating Heritage and Inspiring Change ft. Arbeena Thapa',\n",
       " 'Women in tech: Panelist Spotlight – Magdalena Rahn',\n",
       " 'Women in tech: Panelist Spotlight – Rachel Robbins-Mayhill',\n",
       " 'Women in Tech: Panelist Spotlight – Sarah Mellor',\n",
       " 'Women in Tech: Panelist Spotlight – Madeleine Capper',\n",
       " 'Black Excellence in Tech: Panelist Spotlight – Wilmarie De La Cruz Mejia',\n",
       " 'Git Codeupdates']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e72163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blog_content():\n",
    "    \n",
    "    links, new_links = get_blog_links()\n",
    "    \n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "    \n",
    "    all_content = []\n",
    "\n",
    "    for url in new_links:\n",
    "        \n",
    "        response = get(url, headers=headers)\n",
    "    \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        content = soup.select(\".entry-content\")[0].find_all(\"p\")\n",
    "        \n",
    "        all_content.append(content)\n",
    "\n",
    "    clean_content = []\n",
    "\n",
    "    for p in all_content:\n",
    "\n",
    "        clean_content.append(p.get_text())\n",
    "        \n",
    "    joined = ' '.join(clean_content)\n",
    "        \n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2900f14a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m blog_content()\n",
      "Cell \u001b[0;32mIn[88], line 23\u001b[0m, in \u001b[0;36mblog_content\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m clean_content \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m all_content:\n\u001b[0;32m---> 23\u001b[0m     clean_content\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mget_text())\n\u001b[1;32m     25\u001b[0m joined \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(clean_content)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m joined\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/bs4/element.py:2428\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[1;32m   2430\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "blog_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c01b3",
   "metadata": {},
   "source": [
    "# 2. News Articles\n",
    "\n",
    "## We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "## Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "* Business\n",
    "* Sports\n",
    "* Technology\n",
    "* Entertainment\n",
    "## The end product of this should be a function named get_news_articles that returns a list of dictionaries, where each dictionary has this shape:\n",
    "\n",
    "\n",
    "{\n",
    "    'title': 'The article title',\n",
    "    'content': 'The article content',\n",
    "    'category': 'business' # for example\n",
    "}\n",
    "## Hints:\n",
    "\n",
    "* Start by inspecting the website in your browser. Figure out which elements will be useful.\n",
    "* Start by creating a function that handles a single article and produces a dictionary like the one above.\n",
    "* Next create a function that will find all the articles on a single page and call the function you created in the\n",
    "  last step for every article on the page.\n",
    "* Now create a function that will use the previous two functions to scrape the articles from all the pages that you need, and do any additional processing that needs to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efce76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2924e704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afab7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
